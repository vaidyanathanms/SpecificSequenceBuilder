#---------------------------------------------------------------------
# Supporting scripts for seqbuild_main.py
# 'None' is a reserved keyword - DONT USE IT for PDB/PSF filenames
#---------------------------------------------------------------------

# Import modules
import os
import sys
import numpy
import re
import shutil
import glob
import random
import collections
import math
import subprocess
from collections import Counter
#---------------------------------------------------------------------

# General copy script
def gencpy(dum_maindir,dum_destdir,fylname):

    srcfyl = dum_maindir + '/' + fylname

    if not os.path.exists(srcfyl):
        print('ERROR: ', srcfyl, 'not found')
        return

    desfyl = dum_destdir + '/' + fylname
    shutil.copy2(srcfyl,desfyl)
#---------------------------------------------------------------------

# Set defaults
def def_vals():
    return 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2.0
#---------------------------------------------------------------------

# Check all flags 
def check_all_flags(casenum,disflag,M,N,fnamd,fpdbflag,ftopflag):
    outflag = 1
    if casenum < 0:
        print('ERR: Case number not input'); outflag = -1
    elif N == 0:
        print('ERR: No chains found in input'); outflag = -1
    elif disflag == 0 and M == 0:
        print('ERR: Monodisperse systems with no MW'); outflag = -1
    elif ftopflag == 0:
        print('ERROR: Topology file not found')
    elif fnamd != 0 and fpdbflag == 0:
        print('ERROR: To run NAMD, input PDB/top files are required')
        outflag = -1
    return outflag
#---------------------------------------------------------------------

# Define headers for psf files
def psfgen_headers(fin,topname,outname):
    fin.write(';# headers and inputs \n')
    fin.write('package require psfgen \n')
    topinp = '../' + topname
    fin.write('%s\t %s\n' %('topology',topinp))
#---------------------------------------------------------------------              
# Details for closing input files
def psfgen_postprocess(fin,writetype,iter_num,segname,fnamdflag,\
                       basic_pdb):
    # outname is already there. no need again
    fin.write(';# Writing output \n')
    fin.write('regenerate angles dihedrals \n')

    if fnamdflag:
        if writetype == 'single':
            comnt = 'Reference PDB'
            comnt2 = 'Guesses rest of the coordinates from PDB inp'
            pdbfyle =  '../' + basic_pdb
        elif writetype == 'multi':
            if iter_num == 1:
                comnt = 'Use reference PDB in the first iteration'
                pdbfyle =  '../' + basic_pdb
            else:
                comnt = '*.coor is the file generated by NAMD'
                pdbfyle = '$outputname.coor'

            comnt2 = 'Can create steric clashes and hence the iterations.'
        else:
            exit('ERROR: Unknown option: ' + writetype)
        fin.write('coordpdb %s  %s  ;#  %s\n' %(pdbfyle,segname,comnt))
        fin.write('guesscoord ;#  %s\n' %(comnt2))        
        fin.write('writepdb $outputname.pdb \n')
        if writetype == 'multi':
            fin.write('writepdb ${outputname}_${count}.pdb \n')#backup


    fin.write('writepsf $outputname.psf \n')
    if writetype == 'multi':
        fin.write('writepdb ${outputname}_${count}.psf \n')
#---------------------------------------------------------------------

# Initial PDI details if polydisperse chains are to be generated
def init_pdi_write(pdival,avgmw,nch,op_file,npdiatt,pditolval):
    pdi_fyl = 'inp_genpdi.txt'
    finit   = open(pdi_fyl,'w')
    finit.write('chain_types\n')
    finit.write('%d\n' %(1)) # for now one chain type
    finit.write('chain_details\n')
    finit.write('%g\t %g\t %g\n' %(pdival,avgmw,nch))
    finit.write('max_attempts\n')
    finit.write('%d\n' %(npdiatt))
    if pditolval != 0:
        finit.write('tolerance\n')
        finit.write('%g\n' %(pditolval))
    finit.write('pdi_op_file\n')
    finit.write('%s\n' %(op_file))
    finit.close()
#---------------------------------------------------------------------

# Compile and run PDI. 
def compile_and_run_pdi(destdir):
    
    if not os.path.exists('inp_genpdi.txt'):
        print('inp_genpdi.txt not found')
        return -1
        
    # Generate PDI data
    print("Compiling program to generate polydisperse chains...")
    print("Takes about 10 seconds..")
    if shutil.which("ifort") != None:
        subprocess.call(["ifort","-r8","pdi_dist_params.f90","pdigen.f90",\
                         "-o","pdiinp.o"])
    elif shutil.which("gfortran") != None:
       subprocess.call(["gfortran","-freal-4-real-8",\
                    "pdi_dist_params.f90","pdigen.f90","-o","pdiinp.o"])
    else:
        raise RuntimeError("No Fortran 90 compiler found!")

    print("Compilation successful..")
    subprocess.call(["./pdiinp.o", "inp_genpdi.txt"])
    return 1
#---------------------------------------------------------------------

# Assign MW for polydisperse cases
def make_polydisp_resids(inpfyle, nch):
    if not os.path.exists(inpfyle):
        print('ERR: PDI file: ', inpfyle, 'not found')
        return -1, 0
    chflag = 0
    with open(inpfyle) as fyle_pdi:
        for line in fyle_pdi:
            line = re.split('\W+',line.strip())
            if chflag == 0:
                if len(line) != 2 or line[0] != 'num_chains':
                    print('ERR: Unknown first line in: ', inpfyle)
                    print(line, '\n', len(line), line[0])
                    return -1, 0
                numch = int(line[1])
                chflag = 1
                resmw_data = []
            else:
                if int(line[0]) < 3:
                    print('ERR: Minimum 3 residues should be present')
                    return -1, 0
                resmw_data.append(int(line[0]))

    if len(resmw_data) != nch or nch != numch:
        print('ERR: Mismatch in number of chains')
        print(len(resmw_data), nch, numch)
        return -1, 0

    num_avg_mw = 0; wt_avg_mw = 0
    for mws in range(len(resmw_data)):
        num_avg_mw += resmw_data[mws]
        wt_avg_mw  += pow(resmw_data[mws],2)
    
    wt_avg_mw  = wt_avg_mw/num_avg_mw
    num_avg_mw = num_avg_mw/nch
    pdiout = wt_avg_mw/num_avg_mw

    return resmw_data, pdiout
#---------------------------------------------------------------------

# Initiate log file
def init_logwrite(flog,casenum,bmtype,Marr,tfile,segname,\
              nch,opstyle,disflag,pdiinp):

    flog.write('Case number: %d\n' %(casenum))
    flog.write('Creating TCL file for %s\n' %(bmtype))

    if disflag == 0:
        flog.write('Monodisperse system \n')
        flog.write('Num Chains/num Residues: %d\t%d\n'%(nch,Marr[0]))
    else:
        flog.write('Polydisperse system \n')
        for i in range(len(Marr)):
            flog.write('Chain#/Num Residues: %d\t%d\n' %(i+1,Marr[i]))

    flog.write('PDI: %g\n' %(pdiinp))
    flog.write('Tot res/pat: %d\t%d\n' %(sum(Marr),sum(Marr)-len(Marr)))
    flog.write('Input Topology file file: %s\n' %(tfile))
    flog.write('Segment name in input (or output prefix): %s\n' \
               %(segname))
    flog.write('Output style: %s\n' %(opstyle))
    
    flog.write('Beginning chain generation..\n')
#---------------------------------------------------------------------

# Check initial files
def find_init_files(fpdbflag,fnamdflag,makepdifile,input_top='none',\
                    input_pdb='none'):
    # Read defaults and throw exceptions
    if not os.path.exists(input_top):
        print('Topology file not found \n', input_top)
        return -1
    elif fnamdflag:
        if fpdbflag and not os.path.exists(input_pdb):
            print('Initial structure file not found \n', input_pdb)
            return -1
    elif makepdifile == 1:
        if not os.path.exists('pdigen.f90') or \
           not os.path.exists('pdi_dist_params.f90'):
            print('Source file to generate PDIs not found')
            return -1
    return 1
#---------------------------------------------------------------------

# Create cumulative probability distribution from a dictionary
def cumul_probdist(inpdict,flog):

    dummy_distarr = []

    # store first value
    val = list(inpdict.values())[0]
    dummy_distarr.append(val)

    # add rest of the values
    for key in range(len(inpdict)-1):#iterate until n-1 elements
        val = dummy_distarr[key] + list(inpdict.values())[key+1]
        dummy_distarr.append(val)

    # check normalization
    if abs(dummy_distarr[len(dummy_distarr)-1]-1) > pow(10,-5):
        print('Warning: data not normalized (', \
              dummy_distarr[len(dummy_distarr)-1],\
              '). Forcing normalization')
        flog.write('%s\t%g\t%s\n' %('Warning: data not normalized (', \
                                    dummy_distarr[len(dummy_distarr)-1],\
                                    '). Forcing normalization'))
        sumval = dummy_distarr[len(dummy_distarr)-1]
        
        # force normalization
        for cnt in range(len(dummy_distarr)):
            dummy_distarr[cnt] = dummy_distarr[cnt]/sumval
            
        print('New distribution: ', dummy_distarr)
            
    else:
        print('Generated target cumulative distribution..')

    return dummy_distarr
#---------------------------------------------------------------------

# Check whether the input pdb file is consistent with the inputs given
# for generating the tcl file
def check_pdb_defaults(inpfyle,defa_res,seginp):
    flag = 1 # default true
    resnum = 1
    # Check whether pdb file contains default segment and segment name
    with open(inpfyle) as fpdbin:
        for line in fpdbin:
            line = line.rstrip('\n')
            all_words = re.split('\W+',line)
            if all_words[0] == 'ATOM':
                lenwords = len(all_words)
                if all_words[lenwords-1] != seginp and \
                   all_words[lenwords-2] != seginp:
                    print(all_words[lenwords-1],all_words[lenwords-2])
                    print('Did not find ',seginp,'in ',line)
                    flag = -1
                    break
                if defa_res not in all_words:
                    print('Did not find ',defa_res,'in ',line)
                    flag = -1
                    break
                if all_words[4].isdigit():
                    if int(all_words[4]) > resnum:
                        print('WARNING: More than one res found: ',\
                              resnum)
                        resnum = int(all_words[4])
                else:
                    print('ERR: Unknown value for chain num',\
                          all_words[4])
                    flag = -1


    return flag
#---------------------------------------------------------------------
    
# Create residue sequence
def create_seq_resid_pat(nresarr,nch,segpref,flog,graftopt,nblocks,\
                         nres_types,backbone_res,backbone_pat):

    # Write list to a log file
    flog.write(';#  Entire segment list\n')
    for i in range(nch):
        flog.write(';#  chain_id, #_residues, #_patches: %d\t%d\t%d\n'\
                   %(i+1,nresarr[i], nresarr[i]-1)

    sum_of_res = sum(nresarr)
    sum_of_pat = sum_of_res - nch
    flog.write('; Total residues/patches: %d\t%d\n'\
               %(sum_of_res,sum_of_pat))

    res_list = [[] for i in range(nch)] # output list of residues
    pat_list = [[] for i in range(nch)] # output list of patches
    # Subtract number of branches before adding the backbone list
    if graft_opt[0]:
        br_res_ch = [] # branch residues per chain
        for chcnt in range(nch):
            deg_poly_chain = nresarr[chcnt]; br_cnt = 0
            for ival in range(3,len(graft_opt),3):
                rep_freq = int(graft_opt[ival]) #repeat frequency
                # for every branch, add one backbone mon
                br_cnt += int(deg_poly_chain/(rep_freq+1))
            br_res_ch.append(br_cnt)
            
    # Generate list for backbone    
    for chcnt in range(nch):
        segname = segpref + str(chcnt+1)
        flog.write(';# chain number:\t%d\n' %(chcnt+1))
        n_bb_mons = nresarr[chcnt] - br_res_ch[chcnt]
        if n_bb_mons <= 1: #ERROR
            print('ERROR: Unphysical number of backbone monomers')
            print('Average degree of polymerization may be small')
            return -1
        flist.write('; backbone/branch: %d  %d' \
                    %(n_bb_mons,br_res_ch[chcnt]))
        flist.write(' resetpsf\n')   
        flist.write(' segment %s {\n' %(segname))
        rescntr = 0; blockcount = 0; restyp_cnt = 0
        while rescntr < n_bb_mons:
            while restype < nres_types:
                appendctr = 0
                while appendctr < int(backbone_res[3*restype+2)]):
                    resname1 = backbone_res[3*restype]
                    out_list[chcnt].append(resname1)
                    flist.write(' residue\t%d\t%s\n' \
                                %(rescntr+1,resname1))
                    rescntr += 1; appendctr += 1
                    if rescntr >= n_bb_mons: #exit
                        restype = nres_types+1
                        appctr  = backbone_res[restype+1]+1
                restype += 1 # end appctr loop; jump to next res
            if nblocks > 1: #end restype loop; reloop
                restype = 0
        # Generate list for branches (little expensive to re-do it
        # here; but will make the output cleaner)
        if graft_opt[0]:
            for ival in range(3,len(graft_opt),3):
                rep_freq = int(graft_opt[ival])
                num_br   = int(nresarr[chcnt]/rep_freq)
                resname1 = graft_opt[ival+1]
                out_list[chcnt].append(resname1)
                flist.write(' residue\t%d\t%s\n' \
                            %(rescntr+1,resname1))
                rescntr += 1

    # After going through all the chains, count each residue
    count_res = Counter(out_list)

    #check sum and write output
    sumval = sum(count_res.values())
    if sumval != sum_of_res:
        print('Sum from distn,sum_of_res:',sumval,sum_of_res)
        exit('ERROR: Sum not equal to the total # of residues')

    # Write to log file
    for wout in range(len(outdist)):
        flog.write('%g\t' %(outdist[wout]/sumval))
#---------------------------------------------------------------------

# create patch sequence
def create_seq_patches(flist,nresarr,nch,segpref,flog,graft_opt,\
                       nblocks,nres_types,backbone_seq,backbone_pats):

    # Write list to a separate file
    flist.write(';# Entire patch list\n')
    for i in range(nch):
        flist.write(';#  num_patches\t%d, chain#\t%d\n' \
                    %(nresarr[i]-1,i+1))

    sum_of_res = sum(nresarr)
    sum_of_pat = sum_of_res - nch
       
    flist.write(';# Total number of patches\t%d\n' %(sum_of_pat))
    flist.write(';# -- Begin patches for %s ---\n' %(segname))
    
    out_list = [[] for i in range(nch)] # output list of patches

    # Generate list for backbone
    for chcnt in range(nch):
        segname = segpref + str(chcnt+1)
        flist.write(';# chain number:\t%d\n' %(chcnt+1))
        deg_poly_chain = nresarr[chcnt]

        for blockcount in range(nblocks):
            pattyp_cnt = 0; resnum = 0
            while pattyp_cnt < 2*nres_types-1:
                #append backbone_res[resnum+1]-1 times for restype_i
                for appctr in range(int(backbone_res[resnum+1])-1):
                    out_list[chcnt].append(backbone_pat[pattyp_cnt])
                #append restype_i-restype_i+1 patch, if nrestypes>1
                pattyp_cnt += 1
                if nres_types > 1:
                    out_list[chcnt].append(backbone_pat[pattyp_cnt])
                    pattyp_cnt += 1
            if nblocks > 1:
                out_list[chcnt].append(backbone_pat[pattyp_cnt])

    # Generate list for branches if grafted
    for chcnt in range(nch):
        

    # After going through all the chains, count each patch
    count_res = Counter(out_list)

    #check sum and write output
    sumval = sum(count_res.values())
    if sumval != sum_of_pat:
        print('Sum from distn,sum_of_res:',sumval,sum_of_pat)
        exit('ERROR: Sum not equal to the total # of patches')

    # Write to log file
    for wout in range(len(outdist)):
        flog.write('%g\t' %(outdist[wout]/sumval))
        
#---------------------------------------------------------------------

# Find patch for Case 1: when RES1 and RES2 are normal residues.
def write_normal_patch(cumulprobarr,pat_dict,resname1,resname2,\
                       ctr_flag,patincnt,presctrfyle,ppctrlist,\
                       graft_opt,curpat_list,chcnt,patchname_L):

    ranval = random.random() #seed is current system time by default    
    findflag = 0
    arrcnt = 0

    while arrcnt <= len(cumulprobarr):
        
        #Only need to check the less than value because
        #the array is organized in increasing order.
        #Break the loop once the first point where the
        #condition is met.
        if ranval < cumulprobarr[arrcnt]:

            patchname = list(pat_dict.keys())[arrcnt]
            if patchname in graft_opt: 
                ranval = random.random() #generate new random number
                arrcnt = 0 #reset while loop
                continue # iterate until normal patch

            findflag = 1
            
            # Add constraint flags: default to TRUE
            #so that if constraints are not there, it will
            #be appended. consec flag has to be 0 for true
            appendflag = 1; consecpatflag = 0 
            if ctr_flag != 0:
                if patincnt == 0:
                    resname_L = 'None'
                else:
                    resname_L = resname1
                        
                # end if patcnt == 0
                resname_R = resname2
                if ctr_flag == 1 or ctr_flag == 3:
                    appendflag = check_constraints(presctrfyle,patchname,\
                                                   resname_L,resname_R)
                elif ctr_flag == 2 or ctr_flag == 3:
                    consecpatflag =is_forbid_patch(patchname_L,\
                                                   patchname,ppctrlist)
                # patchname cannot follow patchname_L

                # end if ctr_flag==1

            break

        else: # if ranval > cumulprobarr[arrcnt]
            
            arrcnt += 1 # update array counter
                
        # end ranval < cumulprobarr[]

    # end while arrcnt in range(len(cumulprobarr))

    if findflag != 1:
        print('Random value/Probarr:', ranval,cumulprobarr)
        print('Error: Did not find a random residue\n')
        patchname = 'ERR'
    # end if find flag
    
    return patchname,appendflag,consecpatflag
#---------------------------------------------------------------------

# Write residues/patches in one go -- OBSOLETE. 
# Added in write_multi_segments
def write_segments_onego(fin,nresarr,nch,chnum,segname,res_list,\
                         patch_list,graft_opt):

    fin.write(';# ------Begin main code -----\n')
    fin.write(';# Writing % segments' %(sum(nresarr)))
    fin.write(';# Writing output for %d' %(chnum))
    fin.write(' resetpsf \n')
    fin.write(' segment %s {\n' %(segname))
    
    #Residues
    for rescnt in range(nresarr):
        fin.write('  residue  %d  %s\n' \
                  %(rescnt+1,res_list[chnum-1][rescnt]))

    fin.write('}')        
    fin.write('\n')

    #Patches
    for patcnt in range(max(nresarr)-2):
            
        resname1 = res_list[chnum-1][patcnt]
        resname2 = res_list[chnum-1][patcnt+1]
        patchname = patch_list[chnum-1][patcnt]

        # Normal Case: (see create_patches)
        if resname1 not in graft_opt and resname2 not in graft_opt:
            fin.write('patch  %s  %s:%d  %s:%d\n' \
                      %(patchname,segname,patcnt+1,segname,patcnt+2))


        # Special Case 1: (see create_patches)
        elif resname1 in graft_opt:
            fin.write('patch  %s  %s:%d  %s:%d\n' \
                          %(patchname,segname,patcnt+1,segname,patcnt+2))

        # Special Case 2: (see create_patches)
        elif resname2 in graft_opt:

            # Case 2a: last RES is graft. Patch graft between
            # n and n+1
            if patcnt == max(nresarr)-2: 
                fin.write('patch  %s  %s:%d  %s:%d\n' \
                          %(patchname,segname,patcnt+1,segname,patcnt+2))

            #Case 2b: patch normal between n and n+2
            else: 
                fin.write('patch  %s  %s:%d  %s:%d\n' \
                          %(patchname,segname,patcnt+1,segname,patcnt+3))
                    
        else: # Error
            print('Unknow res/patch sequence')
            print('ch#/patch#' , chnum, patcnt)
            print(res_list)
            print(patch_list)

 
    fin.write('\n')
#---------------------------------------------------------------------

# Write residues/patches iteration by iteration
def write_multi_segments(fin,iter_num,nresthisiter,nch,chnum,\
                         segpref,res_list,patch_list,graft_opt,\
                         maxnummons):

    # Extra condition to account for the graft monomer happening at
    # the end of a PARTIAL segment. Since mth graft is attached to
    # n+1th residue (except when it is at the end of a FULL segment),
    # the n+1th residue has to be a normal residue. Since two graft
    # residues cannot be adjacent, it suffices to add n+1th residue to
    # that iteration.
    if nresthisiter != maxnummons:
        if res_list[chnum-1][nresthisiter-1] in graft_opt:
            nresthisiter += 1

    if iter_num == -1 or iter_num == 1:
        fin.write(';# Chain number: %d of %d chains\n' %(chnum,nch))
        fin.write(';# ----Begin main code -------\n')
        fin.write('\n')

    if iter_num != -1:
        fin.write(';# Iteration number: %d\n' %(iter_num))
        fin.write('set count %d' %(nresthisiter))
        fin.write('\n')


    segname = segpref + str(chnum)
    fin.write(' resetpsf \n')
    fin.write(' segment %s {\n' %(segname))

    #Residues -- indices should have -1 for first dimension  
    for rescnt in range(nresthisiter):
        fin.write('  residue  %d  %s\n' %(rescnt+1,\
                                          res_list[chnum-1][rescnt]))

    fin.write('}')        
    fin.write('\n')
    fin.write('\n')

    #Patches -- ch indices should have -1 for first dimension
    for patcnt in range(nresthisiter-1):
        resname1 = res_list[chnum-1][patcnt]
        resname2 = res_list[chnum-1][patcnt+1]
        patchname = patch_list[chnum-1][patcnt]

        # Normal Case: (see create_patches)
        if (resname1 not in graft_opt) and (resname2 not in graft_opt):
            # Add extra letter to patches for consistency with top file
            # Only for B5 residues. May want to write it as an extra
            # wrapper later for generic cases
            if patchname == 'B5' and resname2 == 'GUAI':
                patchname = 'B5G'
            elif patchname == 'B5' and resname2 == 'PHP':
                patchname = 'B5P'
            elif patchname == 'B5' and resname2 == 'CAT':
                patchname = 'B5C'
            fin.write('patch  %s  %s:%d  %s:%d\n' \
                      %(patchname,segname,patcnt+1,segname,patcnt+2))

        # Special Case 1: (see create_patches)
        elif resname1 in graft_opt:
            fin.write('patch  %s  %s:%d  %s:%d\n' \
                      %(patchname,segname,patcnt+1,segname,patcnt+2))
            
        # Special Case 2: (see create_patches)
        elif resname2 in graft_opt:

            # Case 2a: last RES is graft. Patch graft between
            # n and n+1
            if patcnt == nresthisiter-2: 
                fin.write('patch  %s  %s:%d  %s:%d\n' \
                          %(patchname,segname,patcnt+1,segname,patcnt+2))

            #Case 2b: patch normal between n and n+2
            else: 
                # Add extra letter to patches for consistency with top file
                # Only for B5 residues. May want to write it as an extra
                # wrapper later for generic cases
                resname3 = res_list[chnum-1][patcnt+2]
                if patchname == 'B5' and resname3 == 'GUAI':
                    patchname = 'B5G'
                elif patchname == 'B5' and resname3 == 'PHP':
                    patchname = 'B5P'
                elif patchname == 'B5' and resname3 == 'CAT':
                    patchname = 'B5C'

                fin.write('patch  %s  %s:%d  %s:%d\n' \
                          %(patchname,segname,patcnt+1,segname,patcnt+3))
                    
        else: # Error
            print('Unknow res/patch sequence')
            print('ch#/patch#' , chnum, patcnt)
            print(res_list)
            print(patch_list)

    fin.write('\n')
#---------------------------------------------------------------------

# Run generic namd script
def run_namd(fin,execfyle,inpfyle,outfyle):
    fin.write(';# Run NAMD\n')
    fin.write('%s  %s  > %s\n' %(execfyle,inpfyle,outfyle))        
    fin.write(';# exit \n')
    fin.write(';# -------------------------------------\n')
    fin.write('\n')
#---------------------------------------------------------------------

def initiate_packmol(fpin,inptype,chains,tolval):
    fpin.write('# PACKMOL melt input for %s\n' %(inptype))
    fpin.write('# Contains num chains: %d with tolerance of %g Ang\n'\
               %(chains, tolval))
    fpin.write('\n')
    fpin.write('tolerance %g\n' %(tolval))
    fpin.write('\n')

    fpin.write('# Input filetype\n')
    fpin.write('filetype pdb\n')
    fpin.write('\n')

    outname = 'melt_' + inptype + '_nch_' + str(chains) + '.pdb'
    fpin.write('# Output filename\n')
    fpin.write('output %s\n' %(outname))
    fpin.write('\n')
    fpin.write('# Adding chains\n')
#---------------------------------------------------------------------

# Make packmol input scripts
def make_packmol(fpin,structname,nrepeats,trans_list):
    fpin.write('structure %s\n' %(structname+'.pdb'))
    fpin.write('\t number %d\n' %(nrepeats))
    if trans_list != []:
        fpin.write('\t fixed')
        for k in range(6):
            fpin.write('\t %s' %(trans_list[k]))
        fpin.write('\n')
    fpin.write('end structure\n')
    fpin.write('\n')
#---------------------------------------------------------------------

# Make auxiliary files for NAMD/LigninBuilder/GROMACS
def make_auxiliary_files(tcldir,pref_pdbpsf,nch,topname,input_lbd):


    # bundle.tcl for generating all psf in one go
    fbund = open(tcldir + '/step1.tcl','w')
    fbund.write('# Combined file to generate psf files for all chains\n')
    fbund.write('# Use source step1.tcl from Tk console to run\n')
    
    # combine_psf.tcl() to combine psf/pdb files and write GROMACS
    # generator if neeeded
    outname = pref_pdbpsf + '_nch_' + str(nch)
    inpname = pref_pdbpsf + '_chnum_' 
    topinp = '../' + topname
    fcomb = open(tcldir + '/step2.tcl','w')
    fcomb.write('# To generate combined psf/pdb file..\n')    
    fcomb.write('package require psfgen\n')
    fcomb.write('%s %s %s\n' %('set','name',outname))
    fcomb.write('%s %s\n' %('topology',topinp))
    fcomb.write('resetpsf\n')
    fcomb.write('\n')
    fcomb.write('%s %s %s\n' %('for {set i 1} {$i <= ', str(nch), \
                             ' }  {incr i} {'))
    fcomb.write('%s %s\n' %('readpsf', inpname+str('$i.psf')))
    fcomb.write('%s %s\n' %('coordpdb', inpname+str('$i.pdb')))
    fcomb.write('}\n')
    fcomb.write('writepdb $name.pdb\n')
    fcomb.write('writepsf $name.psf\n')

    fcomb.write('exit\n')
    fcomb.close()
    
    return fbund
#---------------------------------------------------------------------
